{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 23.4       |\n",
      "|    ep_rew_mean        | 23.4       |\n",
      "| time/                 |            |\n",
      "|    fps                | 2847       |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 0          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.693     |\n",
      "|    explained_variance | 0.14653832 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -0.798     |\n",
      "|    value_loss         | 15.2       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 24.8        |\n",
      "|    ep_rew_mean        | 24.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 3208        |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 0           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -0.678      |\n",
      "|    explained_variance | 0.094625175 |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | 0.149       |\n",
      "|    value_loss         | 36          |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 24.8        |\n",
      "|    ep_rew_mean        | 24.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 3395        |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 0           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -0.69       |\n",
      "|    explained_variance | 0.029854715 |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | 1.57        |\n",
      "|    value_loss         | 6.66        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 29.7       |\n",
      "|    ep_rew_mean        | 29.7       |\n",
      "| time/                 |            |\n",
      "|    fps                | 3500       |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 0          |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.66      |\n",
      "|    explained_variance | -0.0190233 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | 1.42       |\n",
      "|    value_loss         | 6.32       |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 32.7          |\n",
      "|    ep_rew_mean        | 32.7          |\n",
      "| time/                 |               |\n",
      "|    fps                | 3546          |\n",
      "|    iterations         | 500           |\n",
      "|    time_elapsed       | 0             |\n",
      "|    total_timesteps    | 2500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -0.619        |\n",
      "|    explained_variance | -0.0148233175 |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 499           |\n",
      "|    policy_loss        | 1.16          |\n",
      "|    value_loss         | 5.67          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 37.6         |\n",
      "|    ep_rew_mean        | 37.6         |\n",
      "| time/                 |              |\n",
      "|    fps                | 3580         |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 0            |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -0.578       |\n",
      "|    explained_variance | -0.011315346 |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | 0.795        |\n",
      "|    value_loss         | 4.97         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 41.7         |\n",
      "|    ep_rew_mean        | 41.7         |\n",
      "| time/                 |              |\n",
      "|    fps                | 3593         |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 0            |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -0.441       |\n",
      "|    explained_variance | 0.0008506179 |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | 1.67         |\n",
      "|    value_loss         | 4.33         |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 43.4           |\n",
      "|    ep_rew_mean        | 43.4           |\n",
      "| time/                 |                |\n",
      "|    fps                | 3586           |\n",
      "|    iterations         | 800            |\n",
      "|    time_elapsed       | 1              |\n",
      "|    total_timesteps    | 4000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -0.622         |\n",
      "|    explained_variance | -3.5762787e-07 |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 799            |\n",
      "|    policy_loss        | -12.6          |\n",
      "|    value_loss         | 1.13e+03       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 45.7           |\n",
      "|    ep_rew_mean        | 45.7           |\n",
      "| time/                 |                |\n",
      "|    fps                | 3591           |\n",
      "|    iterations         | 900            |\n",
      "|    time_elapsed       | 1              |\n",
      "|    total_timesteps    | 4500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -0.531         |\n",
      "|    explained_variance | -0.00048339367 |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 899            |\n",
      "|    policy_loss        | 0.429          |\n",
      "|    value_loss         | 3.34           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 48.5          |\n",
      "|    ep_rew_mean        | 48.5          |\n",
      "| time/                 |               |\n",
      "|    fps                | 3608          |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 1             |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -0.45         |\n",
      "|    explained_variance | 0.00026357174 |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | 1.43          |\n",
      "|    value_loss         | 2.89          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 51.6          |\n",
      "|    ep_rew_mean        | 51.6          |\n",
      "| time/                 |               |\n",
      "|    fps                | 3607          |\n",
      "|    iterations         | 1100          |\n",
      "|    time_elapsed       | 1             |\n",
      "|    total_timesteps    | 5500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -0.61         |\n",
      "|    explained_variance | 9.7453594e-05 |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1099          |\n",
      "|    policy_loss        | 0.81          |\n",
      "|    value_loss         | 2.45          |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 55.8        |\n",
      "|    ep_rew_mean        | 55.8        |\n",
      "| time/                 |             |\n",
      "|    fps                | 3610        |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -0.433      |\n",
      "|    explained_variance | 0.000300169 |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | -40.3       |\n",
      "|    value_loss         | 2.82e+03    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 59            |\n",
      "|    ep_rew_mean        | 59            |\n",
      "| time/                 |               |\n",
      "|    fps                | 3615          |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 1             |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -0.665        |\n",
      "|    explained_variance | 3.8146973e-05 |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | 0.782         |\n",
      "|    value_loss         | 1.7           |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 62.1        |\n",
      "|    ep_rew_mean        | 62.1        |\n",
      "| time/                 |             |\n",
      "|    fps                | 3637        |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -0.603      |\n",
      "|    explained_variance | 4.23193e-06 |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | 0.645       |\n",
      "|    value_loss         | 1.38        |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 66.2           |\n",
      "|    ep_rew_mean        | 66.2           |\n",
      "| time/                 |                |\n",
      "|    fps                | 3646           |\n",
      "|    iterations         | 1500           |\n",
      "|    time_elapsed       | 2              |\n",
      "|    total_timesteps    | 7500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -0.675         |\n",
      "|    explained_variance | -4.4107437e-05 |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1499           |\n",
      "|    policy_loss        | 0.513          |\n",
      "|    value_loss         | 1.08           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 70.6          |\n",
      "|    ep_rew_mean        | 70.6          |\n",
      "| time/                 |               |\n",
      "|    fps                | 3646          |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 2             |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -0.533        |\n",
      "|    explained_variance | -4.887581e-06 |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | -28           |\n",
      "|    value_loss         | 2.01e+03      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 72.6           |\n",
      "|    ep_rew_mean        | 72.6           |\n",
      "| time/                 |                |\n",
      "|    fps                | 3644           |\n",
      "|    iterations         | 1700           |\n",
      "|    time_elapsed       | 2              |\n",
      "|    total_timesteps    | 8500           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -0.642         |\n",
      "|    explained_variance | 0.000100672245 |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 1699           |\n",
      "|    policy_loss        | 0.458          |\n",
      "|    value_loss         | 0.574          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 78.9         |\n",
      "|    ep_rew_mean        | 78.9         |\n",
      "| time/                 |              |\n",
      "|    fps                | 3650         |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 2            |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -0.638       |\n",
      "|    explained_variance | 8.225441e-06 |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.238        |\n",
      "|    value_loss         | 0.385        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 81.9          |\n",
      "|    ep_rew_mean        | 81.9          |\n",
      "| time/                 |               |\n",
      "|    fps                | 3664          |\n",
      "|    iterations         | 1900          |\n",
      "|    time_elapsed       | 2             |\n",
      "|    total_timesteps    | 9500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -0.665        |\n",
      "|    explained_variance | -3.170967e-05 |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1899          |\n",
      "|    policy_loss        | 0.223         |\n",
      "|    value_loss         | 0.228         |\n",
      "-----------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 88       |\n",
      "|    ep_rew_mean        | 88       |\n",
      "| time/                 |          |\n",
      "|    fps                | 3675     |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.602   |\n",
      "|    explained_variance | 0.0      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.106    |\n",
      "|    value_loss         | 0.112    |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import A2C\n",
    "\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "\n",
    "model = A2C(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=10_000)\n",
    "\n",
    "vec_env = model.get_env()\n",
    "obs = vec_env.reset()\n",
    "for i in range(1000):\n",
    "    action, _state = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = vec_env.step(action)\n",
    "    # vec_env.render(\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sohanurrahman/Desktop/College/Research-2024/venv/lib/python3.12/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward over 100 episodes: 500.0 ± 0.0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=100, deterministic=True)\n",
    "print(f\"Mean reward over 100 episodes: {mean_reward} ± {std_reward}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
